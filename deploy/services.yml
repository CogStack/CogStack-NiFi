version: '3.6'

#---------------------------------------------------------------------------#
# Used services                                                             #
#---------------------------------------------------------------------------#
services:

#---------------------------------------------------------------------------#
# Postgres container with sample data                                       #
#---------------------------------------------------------------------------#
  samples-db:
    image: postgres:13.4-alpine
    container_name: cogstack-samples-db
    shm_size: 128mb
    restart: always
    environment:
      # PG env vars
      - POSTGRES_USER=test
      - POSTGRES_PASSWORD=test
    volumes:
      # mapping postgres data dump and initialization
      - ../services/pgsamples/db_dump/db_samples-pdf-text-small.sql.gz:/data/db_samples.sql.gz:ro
      - ../services/cogstack-db/schemas/annotations_nlp_create_schema.sql:/data/annotations_nlp_create_schema.sql:ro
      - ../services/pgsamples/init_db.sh:/docker-entrypoint-initdb.d/init_db.sh:ro
      # data persistence
      - samples-vol:/var/lib/postgresql/data
    ports:
    # <host:container> expose the postgres DB to host for debugging purposes
      - 5554:5432
    #expose:
    #  - 5432
    networks:
      - cognet


#---------------------------------------------------------------------------#
# Apache Tika documents processing service                                  #
#---------------------------------------------------------------------------#
  tika-service:
    image: cogstacksystems/tika-service:latest
    container_name: cogstack-tika
    shm_size: 256mb
    restart: always
    environment:
      - http_proxy=$HTTP_PROXY
      - https_proxy=$HTTPS_PROXY
      - no_proxy=$no_proxy
    volumes:
      - ../services/tika-service/config:/app/config:ro
    ports:
      - 8090:8090
    expose:
      - 8090
    networks:
      - cognet


#---------------------------------------------------------------------------#
# NLP Services containers                                                   #
#   * using example free models / resources                                 #
#---------------------------------------------------------------------------#
  nlp-medcat-medmen:
    image: cogstacksystems/medcat-service:dev-latest
    container_name: cogstack-medcat-medmen
    restart: always
    # INFO: MedCAT configuration is specified via 'env' files
    env_file:
      - ../services/nlp-services/applications/medcat/config/env_app
      - ../services/nlp-services/applications/medcat/config/env_medcat
    environment:
      - APP_MODEL_NAME=medmen-demo
      - SERVICE_WORKERS=2 
    # INFO: MedCAT models are mounted via volumes
    volumes:
      - ../services/nlp-services/applications/medcat/models/medmen/cdb.dat:/cat/models/cdb.dat:ro
      - ../services/nlp-services/applications/medcat/models/medmen/vocab.dat:/cat/models/vocab.dat:ro
      - ../services/nlp-services/applications/medcat/models/medmen/Status:/cat/models/mc_status:ro
    #expose:
    #  - 5000
    ports:
      - "5555:5000"
    networks:
      - cognet

  nlp-gate-drugapp:
    image: cogstacksystems/nlp-rest-service-gate:dev-latest
    #build: ../services/nlp-services/applications/drug-app/
    container_name: cogstack-gate-drugapp
    restart: always
    volumes:
      # INFO: CogStack GATE runner configuration files
      - ../services/nlp-services/applications/drug-app/config:/app/nlp-service/config:ro
      - ../services/nlp-services/applications/drug-app/gate:/gate/app/drug-app:ro
    command: "bash /app/nlp-service/run.sh"
    #expose:
    #  - 8095
    ports:
      - "8095:8095"
    networks:
      - cognet

#---------------------------------------------------------------------------#
# NLP Services containers                                                   #
#   * using internal models / resources                                     #
#---------------------------------------------------------------------------#
  nlp-medcat-snomed:
    image: cogstacksystems/medcat-service:latest
    container_name: cogstack-medcat-snomed
    restart: always
    env_file:
      - ../services/nlp-services/applications/medcat/config/env_app
      - ../services/nlp-services/applications/medcat/config/env_medcat
    environment:
      - APP_MODEL_NAME=snomed-mimic
      - RES_MEDCAT_SNOMED_PATH="./"
    volumes:
      - ${RES_MEDCAT_SNOMED_PATH}/cdb.dat:/cat/models/cdb.dat:ro
      - ${RES_MEDCAT_SNOMED_PATH}/vocab.dat:/cat/models/vocab.dat:ro
    expose:
      - 5000
    networks:
      - cognet

  nlp-gate-bioyodie:
    image: cogstacksystems/nlp-rest-service-gate:latest
    container_name: cogstack-gate-bioyodie
    restart: always
    environment:
      - RES_BIOYODIE_UMLS_PATH="./"
    volumes:
      # INFO: CogStack GATE runner configuration files
      - ../services/nlp-services/applications/bio-yodie/config:/app/nlp-service/config:ro
      # TODO: properly set BioYODIE UMLS resources
      # - ${RES_BIOYODIE_UMLS_PATH}:/gate/app/bioyodie/bio-yodie-resources:ro
    #command: "bash /app/nlp-service/run.sh"
    expose:
      - 8095
    networks:
      - cognet


#---------------------------------------------------------------------------#
# MedCAT Trainer                                                            #
#---------------------------------------------------------------------------#
  medcat-trainer-ui:
    image: cogstacksystems/medcat-trainer:latest
    container_name: cogstack-medcat-trainer-ui
    restart: always
    # INFO: MedCAT library config provided via env file
    env_file:
      - ../services/medcat-trainer/envs/env
    environment:
      - http_proxy=$HTTP_PROXY
      - https_proxy=$HTTPS_PROXY
      - no_proxy=$no_proxy
    volumes:
      - medcat-api-media:/home/api/media
      - medcat-api-static:/home/api/static
      - medcat-api-db:/home/api/db
    expose:
      - "8000"
    command: /home/run.sh

  medcat-trainer-nginx:
    image: cogstacksystems/medcat-trainer-nginx:latest
    container_name: cogstack-medcat-trainer-nginx
    restart: always
    environment:
      - http_proxy=$HTTP_PROXY
      - https_proxy=$HTTPS_PROXY
      - no_proxy=$no_proxy
    volumes:
      - ../services/medcat-trainer/nginx/sites-enabled:/etc/nginx/sites-enabled/:ro
      - medcat-api-media:/home/api/media
      - medcat-api-static:/home/api/static
    ports:
      - "8001:8000"
    depends_on:
      - medcat-trainer-ui


#---------------------------------------------------------------------------#
# ElasticSearch cluster                                                     #
#---------------------------------------------------------------------------#
  elasticsearch-1:
    #image: amazon/opendistro-for-elasticsearch:1.12.0
    #image: docker.elastic.co/elasticsearch/elasticsearch:7.14.0
    image: opensearchproject/opensearch:1.0.0
    container_name: cogstack-elasticsearch-1
    platform: linux
    shm_size : 1024mb
    restart: always
    # mem_limit: 2g
    environment:
      - http_proxy=$HTTP_PROXY
      - https_proxy=$HTTPS_PROXY
      - no_proxy=$no_proxy
      # CLUSTER CONFIGS
      - node.name=es01
      - cluster.name=docker-cluster
        # INFO: enable 'zen' for multi-node cluster
      - discovery.type=zen
      # - discovery.type=single-node
      - discovery.seed_hosts=elasticsearch-1,elasticsearch-2
      - cluster.initial_master_nodes=es01,es02
    
      # OTHER SETTINGS
      - bootstrap.memory_lock=true # disables swapping, imporving r/w performance (at the expense of RAM)
      - "ES_JAVA_OPTS=-Xms1G -Xmx1G"
      # INFO: set 'true' to enable SSL, DISABLE THESE IF YOU ARE USING ELASTICSEARCH NATIVE
      # - opendistro_security.disabled=false
      #- opendistro_security.ssl.http.enabled=false
      #- opendistro_security.ssl.transport.enabled=false

      # INFO: set 'true' to enable SSL
      - plugins.security.ssl.http.enabled=false
      #- plugins.security.ssl.transport.enabled=false

      # NATIVE elasticsearch only options:
      - ELASTICSEARCH_USER=kibanaserver
      - ELASTICSEARCH_PASSWORD=kibanaserver
      - ELASTIC_USER=kibanaserver
      - ELASTIC_PASSWORD=kibanaserver
    volumes:
      # INFO: ES configuration mapped via volume (make sure to comment this and uncomment the next line if you are using NATIVE elasticsearch deployment)
      - ../services/elasticsearch/config/elasticsearch_opendistro.yml:/usr/share/elasticsearch/config/elasticsearch.yml:ro
      #- ../services/elasticsearch/config/elasticsearch_native.yml:/usr/share/elasticsearch/config/elasticsearch.yml:ro

      # ES data persistence
      - elasticsearch-vol-1:/usr/share/elasticsearch/data

      # mapping security config
      # INFO: uncomment below to add SSL keys
      #- ../security/root-ca.pem:/usr/share/opensearch/config/root-ca.pem:ro
      #- ../security/es-node1.pem:/usr/share/opensearch/config/esnode.pem:ro
      #- ../security/es-node1.key:/usr/share/opensearch/config/esnode-key.pem:ro

      # common setting for now
      - ../security/internal_users.yml:/usr/share/elasticsearch/plugins/opendistro_security/securityconfig/internal_users.yml:ro

      # open distro /opensearch only
      - ../security/opendistro/roles_mapping.yml:/usr/share/elasticsearch/plugins/opendistro_security/securityconfig/roles_mapping.yml:ro
      - ../security/opendistro/roles.yml:/usr/share/elasticsearch/plugins/opendistro_security/securityconfig/roles.yml:ro
      
      # VM settings
      - ../services/elasticsearch/sysctl.conf:/etc/sysctl.conf:ro 

      # ES data persistence
      - elasticsearch-vol-1:/usr/share/opensearch/data
    ulimits:
      memlock:
        soft: -1
        hard: -1
    ports:
      - "9200:9200"
    expose:
      - 9300
      - 9600
      - 9200
    networks:
      - cognet

  elasticsearch-2:
    #image: amazon/opendistro-for-elasticsearch:1.12.0
    #image: docker.elastic.co/elasticsearch/elasticsearch:7.14.0
    image: opensearchproject/opensearch:1.0.0
    container_name: cogstack-elasticsearch-2
    platform: linux
    shm_size : 1024mb
    restart: always
    # mem_limit: 2g
    environment:
      - http_proxy=$HTTP_PROXY
      - https_proxy=$HTTPS_PROXY
      - no_proxy=$no_proxy
      # CLUSTER CONFIGS
      - node.name=es02
      - cluster.name=docker-cluster
      - discovery.type=zen # INFO: enable "zen" for multi-node cluster
      - discovery.seed_hosts=elasticsearch-1, elasticsearch-2
      - cluster.initial_master_nodes=es01,es02

      # OTHER SETTINGS
      - bootstrap.memory_lock=true # disables swapping, imporving r/w performance (at the expense of RAM)
      - "ES_JAVA_OPTS=-Xms1G -Xmx1G"
      # INFO: set "true" to enable SSL, DISABLE THESE IF YOU ARE USING ELASTICSEARCH NATIVE
      # - opendistro_security.disabled=true
      # - opendistro_security.ssl.http.enabled=false
      # - opendistro_security.ssl.transport.enabled=false

      # INFO: set "true" to enable SSL
      - plugins.security.ssl.http.enabled=false
      #- plugins.security.ssl.transport.enabled=false

      # NATIVE elasticsearch only options:
      - ELASTICSEARCH_USER=kibanaserver
      - ELASTICSEARCH_PASSWORD=kibanaserver
      - ELASTIC_USER=kibanaserver
      - ELASTIC_PASSWORD=kibanaserver
    volumes:
      # INFO: ES configuration mapped via volume (make sure to comment this and uncomment the next line if you are using NATIVE elasticsearch deployment)
      - ../services/elasticsearch/config/elasticsearch_opendistro.yml:/usr/share/elasticsearch/config/elasticsearch.yml:ro
      #- ../services/elasticsearch/config/elasticsearch_native.yml:/usr/share/elasticsearch/config/elasticsearch.yml:ro

      # ES data persistence
      - elasticsearch-vol-2:/usr/share/elasticsearch/data

      # mapping security config
      # INFO: uncomment below to add SSL keys
      #- ../security/root-ca.pem:/usr/share/opensearch/config/root-ca.pem:ro
      #- ../security/es-node1.pem:/usr/share/opensearch/config/esnode.pem:ro
      #- ../security/es-node1.key:/usr/share/opensearch/config/esnode-key.pem:ro

      # common setting for now
      - ../security/internal_users.yml:/usr/share/elasticsearch/plugins/opendistro_security/securityconfig/internal_users.yml:ro

      # open distro /opensearch only
      - ../security/opendistro/roles_mapping.yml:/usr/share/elasticsearch/plugins/opendistro_security/securityconfig/roles_mapping.yml:ro
      - ../security/opendistro/roles.yml:/usr/share/elasticsearch/plugins/opendistro_security/securityconfig/roles.yml:ro
      
      # VM settings
      - ../services/elasticsearch/sysctl.conf:/etc/sysctl.conf:ro
     
      # ES data persistence
      - elasticsearch-vol-2:/usr/share/opensearch/data

    ulimits:
      memlock:
        soft: -1
        hard: -1
    ports:
      - "9201:9200"
    expose:
      - 9300
      - 9600
      - 9200
    networks:
      - cognet


#---------------------------------------------------------------------------#
# Kibana webapp                                                             #
#---------------------------------------------------------------------------#
  kibana:
    #image: amazon/opendistro-for-elasticsearch-kibana:1.12.0
    #image: docker.elastic.co/kibana/kibana:7.14.0
    image: opensearchproject/opensearch-dashboards:1.0.0

    container_name: cogstack-kibana
    restart: always
    #env_file: ./security/es_kibana_user.env
    environment:
      # INFO: use HTTPS instead of HTTP when enabled SSL
      OPENSEARCH_HOSTS: '["http://elasticsearch-1:9200","http://elasticsearch-2:9200"]'
      # INFO: uncomment below to enable SSL keys
      SERVER_SSL_ENABLED: "false"

      ### DEFAULT native kibana-ElasticSearch path ###
      # SERVER_SSL_KEY: /usr/share/kibana/config/kibana.key
      # SERVER_SSL_CERTIFICATE: /usr/share/kibana/config/kibana.pem

      ### OPENSEARCH_VERSION ### use only if you use opensearch instead of native Kibana
      # SERVER_SSL_KEY: /usr/share/opensearch-dashboards/config/kibana.key
      # SERVER_SSL_CERTIFICATE: /usr/share/opensearch-dashboards/config/kibana.pem

    depends_on:
      - elasticsearch-1
      - elasticsearch-2
    volumes:
      # INFO: Kibana configuration mapped via volume (make sure to comment this and uncomment the next line if you are using NATIVE kibana deployment)
      - ../services/kibana/config/kibana_opendistro.yml:/usr/share/kibana/config/kibana.yml:ro    
      #- ../services/kibana/config/kibana_native.yml:/usr/share/kibana/config/kibana.yml:ro    
      
      # INFO: uncomment below to add SSL keys
      #- ./security/root-ca.pem:/usr/share/opensearch-dashboards/config/root-ca.pem:ro
      #- ./security/kibana.pem:/usr/share/opensearch-dashboards/config/kibana.pem:ro
      #- ./security/kibana.key:/usr/share/opensearch-dashboards/config/kibana.key:ro
      # INFO: Kibana configuration mapped via volume
      #- ../services/kibana/config/kibana.yml:/usr/share/opensearch-dashboards/config/opensearch_dashboards.yml
    ports:
      - "5601:5601"
    networks:
      - cognet


#---------------------------------------------------------------------------#
# NiFi webapp                                                               #
#---------------------------------------------------------------------------#
  nifi:
    #image: cogstacksystems/cogstack-nifi:dev-latest
    #image: apache/nifi:latest
    build:
      context: ../nifi/
      args:      
          HTTP_PROXY: $HTTP_PROXY
          HTTPS_PROXY: $HTTPS_PROXY
          no_proxy: $no_proxy
    container_name: cogstack-nifi
    restart: always
    shm_size: 256mb
    volumes:
      # INFO: mapping custom development directory
      - ../nifi/devel:/opt/nifi/devel
      
      # INFO: if there are  local changes, map these content from local host to container
      #       (normally, these 3 directories  below are bundled with our NiFi image)
      #- ../nifi/user-templates:/opt/nifi/nifi-current/conf/templates:ro
      #- ../nifi/user-scripts:/opt/nifi/user-scripts:ro
      #- ../nifi/user-schemas:/opt/nifi/user-schemas:ro

      # INFO: uncomment below to map security certificates if need to secure NiFi endpoints 
      - ../security/nifi-cert.pem:/opt/nifi/nifi-current/security/nifi-cert.pem:ro
      - ../security/nifi-key.key:/opt/nifi/nifi-current/security/nifi-key.key:ro

      - ../security/localhost/keystore.jks:/opt/nifi/nifi-current/conf/keystore.jks:ro
      - ../security/localhost/truststore.jks:/opt/nifi/nifi-current/conf/truststore.jks:ro

      # rest of volumes to persist the state
      - nifi-vol-conf:/opt/nifi/nifi-current/conf
      - nifi-vol-logs:/opt/nifi/nifi-current/logs
      - nifi-vol-provenance:/opt/nifi/nifi-current/provenance_repository
      - nifi-vol-database:/opt/nifi/nifi-current/database_repository
      - nifi-vol-flowfiles:/opt/nifi/nifi-current/flowfile_repository
      - nifi-vol-content:/opt/nifi/nifi-current/content_repository
      # logs
      - ../nifi/nifi-app.log:/opt/nifi/nifi-current/logs/nifi-app.log:rw
      # errors generated during data processing
      - nifi-vol-errors:/opt/nifi/pipeline/flowfile-errors
    environment:
     - http_proxy=$HTTP_PROXY
     - https_proxy=$HTTPS_PROXY
     - no_proxy=$no_proxy

    # INFO : Uncomment the below line to generate your own USERNAME and PASSWORD,
    #        a bit messy this way as you will need to copy the credentials back
    #        to the "login-identity-providers.xml" section.

    #entrypoint: bash -c "/opt/nifi/nifi-current/bin/nifi.sh set-single-user-credentials admin admincogstacknifi"

    privileged: true
    tty: true
    ports:
      - "8080:8080"
      - "8443:8443"
    expose:
      - "10443"
    networks:
      - cognet

#---------------------------------------------------------------------------#
# Jupyter Hub                                                               #
#---------------------------------------------------------------------------#
  jupyter-hub:
    image: lrog/cogstack-jupyter-hub:latest
    build: ../services/jupyter-hub/
    container_name: cogstack-jupyter-hub
    restart: always
    environment:
      - JUPYTER_ENABLE_LAB=yes
    volumes:
      - "../services/jupyter-hub/notebooks:/home/jovyan/notebooks"
      # INFO: uncomment below to map security certificates if needed
      #- "../security/jupyter.pem:/etc/ssl/notebook/jupyter.pem:ro"
      #- "../security/jupyter.key:/etc/ssl/notebook/jupyter.key:ro"
      #- "../security/root-ca.pem:/etc/ssl/notebook/root-ca.pem:ro"
    command: "start-notebook.sh \
                  --NotebookApp.password=${JUPYTERHUB_PASSWORD}"
      # INFO: uncomment below to use SSL keys (as a part of start-up cmd) 
      #           --keyfile=/etc/ssl/notebook/jupyter.key \
      #           --certfile=/etc/ssl/notebook/jupyter.pem \
    ports:
      - "8888:8888"
    networks:
      - cognet
#---------------------------------------------------------------------------#
# Annotation ingester service                                               #
#---------------------------------------------------------------------------#
  annotation-ingester:
     image: cogstacksystems/annotations-ingester:latest
     shm_size : 128mb
     restart: always
     environment:
       - http_proxy=$HTTP_PROXY
       - https_proxy=$HTTPS_PROXY
       - no_proxy=$no_proxy
     volumes:
       - ../services/annotation_ingester/config/config.yml:/app/config/config.yml:ro
     command: "/app/run.sh"
     networks:
      - cognet
    

#---------------------------------------------------------------------------#
# Docker named volumes                                                      #
#---------------------------------------------------------------------------#
volumes:
  samples-vol:
    driver: local

  # ELK-stack related
  elasticsearch-vol-1:
    driver: local
  elasticsearch-vol-2:
    driver: local

  # NiFi related
  nifi-vol-conf:
    driver: local
  nifi-vol-logs:
    driver: local
  nifi-vol-provenance:
    driver: local
  nifi-vol-database:
    driver: local
  nifi-vol-flowfiles:
    driver: local
  nifi-vol-content:
    driver: local
  nifi-vol-errors:
    driver: local

  # MedCAT Trainer
  medcat-api-media:
    driver: local
  medcat-api-static:
    driver: local
  medcat-api-db:
    driver: local


#---------------------------------------------------------------------------#
# Docker networks.                                                          #
#---------------------------------------------------------------------------#
networks:
  cognet:
    name: cogstack-net
